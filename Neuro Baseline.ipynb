{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обратите внимание\nЯ примонтировал эти данные: Fasttext Common Crawl (Russian)\nЭто эмбеддинги для русских слов"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/dmia-dl-nlp-2019/train.csv')\ntest = pd.read_csv('/kaggle/input/dmia-dl-nlp-2019/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom nltk.tokenize import word_tokenize, wordpunct_tokenize\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_text(text):\n    \n    # просто токенизация текста, то есть разбиение предложения на токены (слова)\n    words = wordpunct_tokenize(text.lower())\n    \n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"process_text('красивая мама мыла красивую раму')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# все наши тексты\ntexts = list(train.question.map(process_text)) + list(test.question.map(process_text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# соберем словарь встречаемости слов\n# просто подсчет сколько раз то или иное слово встретилось в наших текстах\n\nword2freq = {}\n\nfor text in texts:\n    \n    for word in text:\n        \n        word2freq[word] = word2freq.get(word, 0) + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Прочитаем файл с векторами\nВ каждой строке этого файла стоит слово, а затем через пробел указано 300 чисел, которые соответствуют эмбеддингу этого слова.\nМы не будем читать все 2 000 000 слов, чтобы не хранить в памяти матрицу из 2 000 000 * 300 чисел. Мы будем добавлять в наш словарь только те слова, которые встречаются в наших текстах.\n\nМы будем добавлять в ```word2index``` слова и их индекс в матрице эмбеддингов\n\nТакже первым словом добавим специальный токен PAD, эмбеддинг которого будет состоять из нулей. Он нужен для дополнения наших предложений до нужной длины, чтобы составить батч из текстов."},{"metadata":{"trusted":true},"cell_type":"code","source":"word2index = {'PAD': 0}\nvectors = []\n    \nword2vec_file = open('/kaggle/input/fasttest-common-crawl-russian/cc.ru.300.vec')\n    \nn_words, embedding_dim = word2vec_file.readline().split()\nn_words, embedding_dim = int(n_words), int(embedding_dim)\n\n# Zero vector for PAD\nvectors.append(np.zeros((1, embedding_dim)))\n\nprogress_bar = tqdm(desc='Read word2vec', total=n_words)\n\nwhile True:\n\n    line = word2vec_file.readline().strip()\n\n    if not line:\n        break\n        \n    current_parts = line.split()\n\n    current_word = ' '.join(current_parts[:-embedding_dim])\n\n    if current_word in word2freq:\n\n        word2index[current_word] = len(word2index)\n\n        current_vectors = current_parts[-embedding_dim:]\n        current_vectors = np.array(list(map(float, current_vectors)))\n        current_vectors = np.expand_dims(current_vectors, 0)\n\n        vectors.append(current_vectors)\n\n    progress_bar.update()\n\nprogress_bar.close()\n\nword2vec_file.close()\n\nvectors = np.concatenate(vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unk_words = [word for word in word2freq if word not in word2index]\nunk_counts = [word2freq[word] for word in unk_words]\nn_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n\nsub_sample_unk_words = {word: word2freq[word] for word in unk_words}\nsorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n\nprint('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\nprint('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\nprint('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\nprint()\nprint('Топ 5 невошедших слов:')\n\nfor i in range(5):\n    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WordData(Dataset):\n    \n    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n        \n        super().__init__()\n        \n        self.x_data = []\n        self.y_data = y_data\n        \n        self.word2index = word2index\n        self.sequence_length = sequence_length\n        \n        self.pad_token = pad_token\n        self.pad_index = self.word2index[self.pad_token]\n        \n        self.load(x_data, verbose=verbose)\n        \n    @staticmethod\n    def process_text(text):\n    \n        words = wordpunct_tokenize(text.lower())\n\n        return words\n        \n    def load(self, data, verbose=True):\n        \n        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n        \n        for text in data_iterator:\n            words = self.process_text(text)\n            indexed_words = self.indexing(words)\n            self.x_data.append(indexed_words)\n    \n    def indexing(self, tokenized_text):\n\n        # выбрасываем неизвестные слова и переводим слова в индекс позиций в матрице эмбеддингов\n\n        return [self.word2index[token] for token in tokenized_text if token in self.word2index]\n    \n    def padding(self, sequence):\n        \n        # Ограничить длину self.sequence_length\n        # если длина меньше максимально - западить\n\n        return sequence[:self.sequence_length] + [self.pad_index] * (self.sequence_length - len(sequence))\n    \n    def __len__(self):\n        \n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        \n        x = self.x_data[idx]\n        x = self.padding(x)\n        x = torch.Tensor(x).long()\n        \n        y = self.y_data[idx]\n        \n        return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(train.question, train.main_category, test_size=0.15)\n\n# train_dataset = WordData(list(x_train), list(y_train), word2index)\n# train_loader = DataLoader(train_dataset, batch_size=64, drop_last=True)\n\ntrain_dataset = WordData(list(train.question), list(train.main_category), word2index)\ntrain_loader = DataLoader(train_dataset, batch_size=64, drop_last=True)\n\nvalidation_dataset = WordData(list(x_validation), list(y_validation), word2index)\nvalidation_loader = DataLoader(validation_dataset, batch_size=64, drop_last=True)\n\ntest_dataset = WordData(list(test.question), np.zeros((test.shape[0])), word2index)\ntest_loader = DataLoader(test_dataset, batch_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in train_loader:\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x - это батч размером 64\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# чтобы составить матрицу мы отрезали длинные предложения до 32 токенов, а короткие дополнили индексом PAD до нужной длины","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# наши таргеты\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes = train.main_category.unique().shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DeepAverageNetwork(torch.nn.Module):\n    \n    def __init__(self, embedding_matrix, n_classes):\n        \n        super().__init__()\n        \n        # здесь мы как раз передаем вектора слов в нашу матрицу эмбеддингов\n        # по умолчанию метод from_pretrained замораживает эту матрицу\n        self.embedding_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix))\n        \n        self.layers = torch.nn.Sequential(\n#                                           torch.nn.Conv1d(300, 256, kernel_size=3),\n#                                           torch.nn.ReLU(),\n#                                           torch.nn.Conv1d(256, 256, kernel_size=5),\n#                                           torch.nn.ReLU(),\n#                                           torch.nn.LSTM(300, 256, batch_first=True), \n#                                           torch.nn.LSTM(256, 128, batch_first=True),\n#                                           torch.nn.LSTM(128, n_classes, batch_first=True),\n#                                           torch.nn.ReLU(), \n#                                           torch.nn.Flatten(),\n                                          torch.nn.Linear(256, 128),\n                                          torch.nn.ReLU(),\n                                          torch.nn.Linear(128, n_classes)\n                                         )\n    def forward(self, x):\n        \n        # переводим индексы слов в вектора\n        x = self.embedding_layer(x)\n        \n        # усредняем эмбеддинги слов\n        # переходим к одну вектору на предложение\n        # обратите внимание, что за счет нулевого токена PAD мы усредняем нечестно, считая, что у всех предложений длина 32 токена\n#         x = x.transpose(1, 2)\n        x = x.mean(dim=-2)\n        \n        \n        # применяем несколько линейных слоев с релу\n        x = self.layers(x)\n        \n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# инициализируем модель\nmodel = DeepAverageNetwork(vectors, n_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# смотрим отработает ли наша модель\n# нет ли багов\nwith torch.no_grad():\n    pred, hidden = model(x, Variable(torch.randn(2, 3, 20))\n\nprint(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = model.embedding_layer(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# эмбеддинги слов\n# 64 - размер батча\n# 32 - количество слов в примере\n# 300 - размер эмбеддинга на каждое слово\nembeddings.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# задаем девайс, где будет учиться модель\n# если доступна гпу, то зададим гпу\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# напомню, что мы не используем в моделе софтмакс, потому что он уже есть здесь\n# criterion = torch.nn.CrossEntropyLoss()\ncriterion = nn.NLLLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n        \n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        pred = model(x)\n#         pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n        y = y.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n            y = y.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # наивный early stopping\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\n\npredictions = []\n\nfor x, _ in test_loader:\n\n    x = x.to(device)\n\n    with torch.no_grad():\n\n        pred , h1 = model(x, h1)\n\n        pred = pred.cpu()\n        \n        predictions.append(np.argmax(pred, axis=1))\n        \npredictions = np.concatenate(predictions).squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['main_category'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test[['index', 'main_category']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.main_category.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SentimentNet(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim=300, hidden_dim=180, n_layers=4, drop_prob=0.2):\n        super(SentimentNet, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n#         weight2 = next(self.parameters()).data\n#         self.hidden2 = (weight2.new(self.n_layers, batch_size, 32).zero_().to(device),\n#                        weight2.new(self.n_layers, batch_size, 32).zero_().to(device))\n        \n        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(vocab_size))\n        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n#         self.lstm2 = nn.LSTM(64, 32, n_layers, dropout=drop_prob, batch_first=True)\n#         self.lstm3 = nn.LSTM(256, 256, n_layers, dropout=drop_prob, batch_first=True)\n#         self.lstm4 = nn.LSTM(256, output_size, n_layers, dropout=drop_prob, batch_first=True)\n        self.bn1 = nn.BatchNorm1d()\n        self.cv1 = nn.Conv1d(180, 180, 3, padding=1)\n        self.mp1 = nn.MaxPool1d(2)\n        \n        self.bn2 = nn.BatchNorm1d()\n        self.cv2 = nn.Conv1d(180, 128, 3, padding=1)\n        self.mp2 = nn.MaxPool1d(2)\n        \n        self.bn2 = nn.BatchNorm1d()\n        self.cv3 = nn.Conv1d(128, 96, 3, padding=1)\n        self.mp3 = nn.MaxPool1d(2)\n        \n        self.cv4 = nn.Conv1d(96, 64, 3, padding=1)\n        \n        self.cv = nn.Conv1d(64, 32, 3, padding=1)\n        \n        self.cv5 = nn.Conv1d(32, 28, 3, padding=1)\n        self.mp5 = nn.MaxPool1d(2)\n        self.cv6 = nn.Conv1d(28, 28, 3, padding=1)\n        self.avp = nn.AvgPool1d(2)\n\n        self.dropout = nn.Dropout(drop_prob)\n        self.fc1 = nn.Linear(128, 64)\n        self.ac1 = nn.ReLU()\n        self.fc2 = nn.Linear(64, output_size)\n        \n    def forward(self, x, hidden1, hidden2):\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding(x)\n#         embeds = torch.nn.utils.rnn.pack_padded_sequence(embeds)\n\n#         embeds = embeds.mean(dim=-2)\n#         print(embeds.shape)\n        lstm_out, hidden1 = self.lstm1(embeds, hidden1)\n#         print(lstm_out.shape)\n#         print(lstm_out.shape)\n#         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n#         lstm_out, hidden = self.lstm2(lstm_out, hidden)\n# #         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n#         lstm_out, hidden = self.lstm3(lstm_out, hidden)\n# #         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n#         lstm_out, hidden = self.lstm4(lstm_out, hidden)\n#         lstm_out = lstm_out[:, -1, :]\n#         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n#         lstm_out, hidden = self.lstm5(lstm_out, hidden)\n# #         lstm_out = nn.utils.rnn.PackedSequence(lstm_out, batch_size)\n        lstm_out = lstm_out.transpose(1, 2)\n#         print(lstm_out.shape)\n        lstm_out = self.cv1(lstm_out)\n        lstm_out = self.mp1(lstm_out)\n        \n        lstm_out = self.cv2(lstm_out)\n        lstm_out = self.mp2(lstm_out)\n        \n        lstm_out = self.cv3(lstm_out)\n        lstm_out = self.mp3(lstm_out)\n        \n        lstm_out = self.cv4(lstm_out)\n        lstm_out = self.mp3(lstm_out)\n        print(lstm_out.shape)\n        \n#         lstm_out = lstm_out.transpose(1, 2)\n# #         print(lstm_out.shape)\n#         lstm_out = self.cv(lstm_out)\n        \n#         lstm_out, hidden2 = self.lstm2(lstm_out, hidden2)\n# #         print(lstm_out.shape)\n        lstm_out = lstm_out.transpose(1, 2)\n#         print(lstm_out.shape)\n#         lstm_out = self.cv5(lstm_out)\n#         lstm_out = self.mp5(lstm_out)\n#         lstm_out = self.cv6(lstm_out)\n#         lstm_out = self.avp(lstm_out)\n#         print(lstm_out.shape)\n# #         lstm_out = lstm_out.transpose(1, 2)\n#         print(lstm_out.shape)\n#         out = lstm_out.view(batch_size, -1)\n            \n        lstm_out = lstm_out.contiguous().view(batch_size, -1)\n        \n        out = self.fc1(lstm_out)\n        out = self.dropout(out)\n        out = self.ac1(out)\n\n        out = self.fc2(out)\n\n        out = out.view(batch_size, -1)\n        \n        return out, hidden1, hidden2\n    \n    def init_hidden(self, batch_size, hidden_dim):\n        weight = next(self.parameters()).data\n        hidden = (weight.new(self.n_layers, batch_size, hidden_dim).zero_().to(device),\n                      weight.new(self.n_layers, batch_size, hidden_dim).zero_().to(device))\n        return hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n        \n        self.supports_masking = True\n\n        self.bias = bias\n        self.feature_dim = feature_dim\n        self.step_dim = step_dim\n        self.features_dim = 0\n        \n        weight = torch.zeros(feature_dim, 1)\n        nn.init.kaiming_uniform_(weight)\n        self.weight = nn.Parameter(weight)\n        \n        if bias:\n            self.b = nn.Parameter(torch.zeros(step_dim))\n        \n    def forward(self, x, mask=None):\n        feature_dim = self.feature_dim \n        step_dim = self.step_dim\n\n        eij = torch.mm(\n            x.contiguous().view(-1, feature_dim), \n            self.weight\n        ).view(-1, step_dim)\n        \n        if self.bias:\n            eij = eij + self.b\n            \n        eij = torch.tanh(eij)\n        a = torch.exp(eij)\n        \n        if mask is not None:\n            a = a * mask\n\n        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n\n        weighted_input = x * torch.unsqueeze(a, -1)\n        return torch.sum(weighted_input, 1)\n\nclass SentimentNet(nn.Module):\n    def __init__(self, vocab_size, output_size, embedding_dim=300, hidden_dim=128, n_layers=4, drop_prob=0.2):\n        super(SentimentNet, self).__init__()\n        self.output_size = output_size\n        self.n_layers = n_layers\n        self.hidden_dim = hidden_dim\n        \n        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(vocab_size))\n#         self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n#         self.lstm2 = nn.LSTM(hidden_dim, 256, n_layers, dropout=drop_prob, batch_first=True)\n#         self.lstm3 = nn.LSTM(256, 256, n_layers, dropout=drop_prob, batch_first=True)\n#         self.lstm4 = nn.LSTM(256, output_size, n_layers, dropout=drop_prob, batch_first=True)\n\n        self.lstm1 = nn.LSTM(embed_size, 128, n_layers, bidirectional=True, dropout=drop_prob, batch_first=True)\n        self.lstm2 = nn.GRU(128*2, 64, bidirectional=True, batch_first=True)\n\n\n        self.cv1 = nn.Conv1d(128, 96, 3, padding=1)\n        self.mp1 = nn.MaxPool1d(2)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.ac0 = nn.ReLU()\n        self.do1 = nn.Dropout()\n        \n        self.cv2 = nn.Conv1d(96, 128, 3, padding=1)\n        self.mp2 = nn.MaxPool1d(2)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.ac2 = nn.ReLU()\n        self.do2 = nn.Dropout()\n        \n#         self.cv3 = nn.Conv1d(64, 128, 3, padding=1)\n#         self.ac3 = nn.ReLU()\n#         self.bn3 = nn.BatchNorm1d(128)\n#         self.mp3 = nn.MaxPool1d(2)\n#         self.do3 = nn.Dropout()\n        \n#         self.cv4 = nn.Conv1d(32, 128, 3, padding=1)\n#         self.ac4 = nn.ReLU()\n#         self.bn4 = nn.BatchNorm1d(128)\n#         self.do4 = nn.Dropout()\n        \n        self.attention_layer = Attention(128, maxlen)\n\n        self.dropout = nn.Dropout(drop_prob)\n        self.fc1 = nn.Linear(2*64, 96)\n        self.bn0 = nn.BatchNorm1d(96)\n        self.ac1 = nn.ReLU()\n        self.fc2 = nn.Linear(96, output_size)\n        self.sigmoid = nn.Softmax()\n        \n    def forward(self, x):\n        batch_size = x.size(0)\n        x = x.long()\n        embeds = self.embedding(x)\n#         embeds = torch.nn.utils.rnn.pack_padded_sequence(embeds)\n\n#         embeds = embeds.mean(dim=-2)\n        lstm_out, hidden = self.lstm1(embeds)\n#         print(lstm_out.shape)\n#         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n        lstm_out, hidden = self.lstm2(lstm_out)\n#         print(lstm_out.shape)\n# #         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n#         lstm_out, hidden = self.lstm3(lstm_out, hidden)\n# #         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n#         lstm_out, hidden = self.lstm4(lstm_out, hidden)\n#         lstm_out = lstm_out[:, -1, :]\n#         lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n\n#         lstm_out, hidden = self.lstm5(lstm_out, hidden)\n# #         lstm_out = nn.utils.rnn.PackedSequence(lstm_out, batch_size)\n        lstm_out = lstm_out.transpose(1, 2)\n\n        lstm_out = self.bn1(lstm_out)\n        lstm_out = self.cv1(lstm_out)\n        lstm_out = self.do1(lstm_out)\n        lstm_out = self.ac0(lstm_out)\n#         lstm_out = self.mp1(lstm_out)\n        \n        lstm_out = self.cv2(lstm_out)\n        lstm_out = self.do2(lstm_out)\n        lstm_out = self.bn2(lstm_out)\n        lstm_out = self.ac2(lstm_out)\n#         lstm_out = self.mp2(lstm_out)\n        \n#         lstm_out = self.cv3(lstm_out)\n#         lstm_out = self.do3(lstm_out)\n#         lstm_out = self.bn3(lstm_out)\n#         lstm_out = self.ac3(lstm_out)\n#         lstm_out = self.mp3(lstm_out)\n        \n#         lstm_out = self.cv4(lstm_out)\n#         lstm_out = self.dropout(lstm_out)\n#         lstm_out = self.bn4(lstm_out)\n#         lstm_out = self.ac4(lstm_out)\n        \n        lstm_out = lstm_out.transpose(1, 2)\n#         print(lstm_out.shape)\n#         lstm_out = lstm_out.contiguous().view(batch_size, -1)\n        lstm_out = self.attention_layer(lstm_out)\n        \n        out = self.fc1(lstm_out)\n        out = self.bn0(out)\n        out = self.dropout(out)\n        out = self.ac1(out)\n\n        out = self.fc2(out)\n\n        out = out.view(batch_size, -1)\n        \n        return out\n    \n    def init_hidden(self, batch_size):\n        weight = next(self.parameters()).data\n        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n        return hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_size = 1\nembedding_dim = 300\nhidden_dim = 128\nn_layers = 2\n\nmodel = SentimentNet(embedding_matrix, n_classes)\nmodel.to(device)\n\nlr=0.01\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\ncriterion = criterion.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_on_gpu = True\nepochs = 10\ncounter = 0\nprint_every = 1000\nclip = 5\nvalid_loss_min = np.Inf\n\nepochs = 15\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nbatch_size = 64\n\nmodel.train()\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n\n    for inputs, labels in train_loader:\n        counter += 1\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        model.zero_grad()\n        \n        output = model(inputs)\n        loss = criterion(output, labels)\n        loss.backward()\n        \n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for inp, lab in validation_loader:\n        inp, lab = inp.to(device), lab.to(device)\n        \n        with torch.no_grad():\n        \n            out = model(inp)\n            out = out.cpu()\n            lab = lab.cpu()\n            \n            test_targets.append(lab.numpy())\n            test_pred_class.append(np.argmax(out, axis=1))\n\n            loss = criterion(out, lab)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n#         if counter%print_every == 0:\n#             val_h = model.init_hidden(batch_size)\n#             val_losses = []\n#             model.eval()\n#             for inp, lab in validation_loader:\n#                 val_h = tuple([each.data for each in val_h])\n#                 inp, lab = inp.to(device), lab.to(device)\n#                 out, val_h = model(inp, val_h)\n#                 val_loss = criterion(out, lab)\n#                 val_losses.append(val_loss.item())\n                \n#             model.train()\n#             print(\"Epoch: {}/{}...\".format(i+1, epochs),\n#                   \"Step: {}...\".format(counter),\n#                   \"Loss: {:.6f}...\".format(loss.item()),\n#                   \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n#             if np.mean(val_losses) <= valid_loss_min:\n#                 torch.save(model.state_dict(), './state_dict.pt')\n#                 print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n#                 valid_loss_min = np.mean(val_losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_losses = []\nnum_correct = 0\nh = model.init_hidden(batch_size)\n\nmodel.eval()\nfor inputs, labels in validation_loader:\n    h = tuple([each.data for each in h])\n    inputs, labels = inputs.to(device), labels.to(device)\n    output, h = model(inputs, h)\n    test_loss = criterion(output, labels)\n    test_losses.append(test_loss.item())\n    pred = torch.round(output)  # Rounds the output to 0/1\n    correct_tensor = pred.eq(labels)\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n    num_correct += np.sum(correct)\n\nprint(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\ntest_acc = num_correct/len(test_loader.dataset)\nprint(\"Test accuracy: {:.3f}%\".format(test_acc*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_size = 300 # how big is each word vector\nmax_features = 244922 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = 32 # max number of words in a question to use\nbatch_size = 64 # how many samples to process at once\nn_epochs = 5 # how many times to iterate over all samples\n# n_splits = 5 # Number of K-fold Splits\n# SEED = 10\n# debug = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = vectors\ndel vectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n        \n        self.supports_masking = True\n\n        self.bias = bias\n        self.feature_dim = feature_dim\n        self.step_dim = step_dim\n        self.features_dim = 0\n        \n        weight = torch.zeros(feature_dim, 1)\n        nn.init.kaiming_uniform_(weight)\n        self.weight = nn.Parameter(weight)\n        \n        if bias:\n            self.b = nn.Parameter(torch.zeros(step_dim))\n        \n    def forward(self, x, mask=None):\n        feature_dim = self.feature_dim \n        step_dim = self.step_dim\n\n        eij = torch.mm(\n            x.contiguous().view(-1, feature_dim), \n            self.weight\n        ).view(-1, step_dim)\n        \n        if self.bias:\n            eij = eij + self.b\n            \n        eij = torch.tanh(eij)\n        a = torch.exp(eij)\n        \n        if mask is not None:\n            a = a * mask\n\n        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n\n        weighted_input = x * torch.unsqueeze(a, -1)\n        return torch.sum(weighted_input, 1)\n\nclass Attention_Net(nn.Module):\n    def __init__(self):\n        super(Attention_Net, self).__init__()\n        drp = 0.1\n#         self.embedding = nn.Embedding(max_features, embed_size)\n        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix))\n#         self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n#         self.embedding.weight.requires_grad = False\n\n        self.embedding_dropout = nn.Dropout2d(0.1)\n        self.lstm = nn.LSTM(embed_size, 128, bidirectional=True, batch_first=True)\n        self.lstm2 = nn.GRU(128*2, 64, bidirectional=True, batch_first=True)\n\n        self.attention_layer = Attention(128, maxlen)\n        \n        self.linear = nn.Linear(64*2 , 64)\n        self.relu = nn.ReLU()\n        self.out = nn.Linear(64, 28)\n\n    def forward(self, x):\n        h_embedding = self.embedding(x)\n        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n        h_lstm, _ = self.lstm(h_embedding)\n        h_lstm, _ = self.lstm2(h_lstm)\n#         print(h_lstm.shape)\n        h_lstm_atten = self.attention_layer(h_lstm)\n#         print(h_lstm_atten.shape)\n        conc = self.relu(self.linear(h_lstm_atten))\n        out = self.out(conc)\n        return out\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Attention_Net()\n\nmodel.to(device)\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\ncriterion.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_on_gpu = True\nprint_every = 1000\nclip = 5\nvalid_loss_min = np.Inf\n\nepochs = 3\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nbatch_size = 64\n\nmodel.train()\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n\n    for inputs, labels in train_loader:\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        model.zero_grad()\n        \n        output = model(inputs)\n        loss = criterion(output, labels)\n        loss.backward()\n        \n        nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for inp, lab in validation_loader:\n        inp, lab = inp.to(device), lab.to(device)\n        \n        with torch.no_grad():\n        \n            out = model(inp)\n            out = out.cpu()\n            lab = lab.cpu()\n            \n            test_targets.append(lab.numpy())\n            test_pred_class.append(np.argmax(out, axis=1))\n\n            loss = criterion(out, lab)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\n\npredictions = []\n\nfor x, _ in test_loader:\n\n    x = x.to(device)\n\n    with torch.no_grad():\n\n        pred = model(x)\n\n        pred = pred.cpu()\n        \n        predictions.append(np.argmax(pred, axis=1))\n        \npredictions = np.concatenate(predictions).squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['main_category'] = predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test[['index', 'main_category']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}